{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import torch\n",
    "import json\n",
    "import shutil\n",
    "import collections\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nnunet.training.model_restore import restore_model\n",
    "from batchgenerators.utilities.file_and_folder_operations import join\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '/executables')\n",
    "from kaapana_federated.kaapana_federated import KaapanaFederatedTrainingBase, requests_retry_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dkfz', 'hamburg']\n"
     ]
    }
   ],
   "source": [
    "class nnUNetFederatedTraining(KaapanaFederatedTrainingBase):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_network_trainer(folder):\n",
    "        checkpoint = join(folder, \"model_final_checkpoint.model\")\n",
    "        pkl_file = checkpoint + \".pkl\"\n",
    "        return restore_model(pkl_file, checkpoint, False)\n",
    "\n",
    "    def __init__(self, run_id=None, workflow_dir=None, federated_operators=None, skip_operators=None):\n",
    "        super().__init__(workflow_dir)\n",
    "        \n",
    "        if self.remote_conf_data['workflow_form']['train_max_epochs'] % self.remote_conf_data['federated_form']['federated_total_rounds'] != 0:\n",
    "            raise ValueError('train_max_epochs has to be multiple of federated_total_rounds')\n",
    "        else:\n",
    "            self.remote_conf_data['workflow_form']['epochs_per_round'] = int(self.remote_conf_data['workflow_form']['train_max_epochs'] / self.remote_conf_data['federated_form']['federated_total_rounds'])\n",
    "\n",
    "        print(f\"Epochs per round {self.remote_conf_data['workflow_form']['epochs_per_round']}\")\n",
    "        \n",
    "    def tensorboard_logs(self, federated_round):\n",
    "        current_federated_round_dir = Path(os.path.join(self.fl_working_dir, str(federated_round)))\n",
    "        for instance_name, _ in self.tmp_federated_site_info.items():\n",
    "            filename = current_federated_round_dir / instance_name / 'nnunet-training' / 'experiment_results.json'\n",
    "            with open(filename) as json_file:\n",
    "                exp_data = json.load(json_file)\n",
    "            tensorboard_log_dir = Path(os.path.join('/minio', 'tensorboard', self.remote_conf_data[\"federated_form\"][\"federated_dir\"], os.getenv('OPERATOR_OUT_DIR', 'federated-operator'), instance_name))\n",
    "            if tensorboard_log_dir.is_dir():\n",
    "                print('Removing previous logs, since we will write all logs again...')\n",
    "                shutil.rmtree(tensorboard_log_dir)\n",
    "            self.writer = SummaryWriter(log_dir=tensorboard_log_dir)\n",
    "            for epoch_data in exp_data:\n",
    "                for key, value in epoch_data.items():\n",
    "                    if key != 'epoch' and key != 'fold':\n",
    "                        self.writer.add_scalar(key, value, epoch_data['epoch'])\n",
    "                \n",
    "    def update_data(self, federated_round):     \n",
    "        print(Path(os.path.join(self.fl_working_dir, str(federated_round))))\n",
    "        self.tensorboard_logs(federated_round)\n",
    "        models_path = Path(os.path.join(self.fl_working_dir, str(federated_round)))\n",
    "        averaged_state_dict = collections.OrderedDict()\n",
    "        averaged_amp_grad_scaler = dict()\n",
    "        print('Loading averaged checkpoints')\n",
    "        for idx, fname in enumerate(models_path.rglob('model_final_checkpoint.model')):\n",
    "            print(fname)\n",
    "            checkpoint = torch.load(fname, map_location=torch.device('cpu'))\n",
    "            if idx==0:\n",
    "                for key, value in checkpoint['state_dict'].items():\n",
    "                    averaged_state_dict[key] = value\n",
    "                if 'amp_grad_scaler' in checkpoint.keys():\n",
    "                    for key, value in checkpoint['amp_grad_scaler'].items():\n",
    "                        averaged_amp_grad_scaler[key] = value \n",
    "            else:\n",
    "                for key, value in checkpoint['state_dict'].items():\n",
    "                    averaged_state_dict[key] =  (averaged_state_dict[key] + checkpoint['state_dict'][key]) / 2.\n",
    "                if 'amp_grad_scaler' in checkpoint.keys():\n",
    "                    for key, value in checkpoint['amp_grad_scaler'].items():\n",
    "                        averaged_amp_grad_scaler[key] = (averaged_amp_grad_scaler[key] + checkpoint['amp_grad_scaler'][key]) / 2.\n",
    "\n",
    "        print('Saving averaged checkpoints')\n",
    "        for idx, fname in enumerate(models_path.rglob('model_final_checkpoint.model')):\n",
    "            print(fname)\n",
    "            checkpoint['state_dict'] = averaged_state_dict\n",
    "#             if 'amp_grad_scaler' in checkpoint.keys():\n",
    "#                 checkpoint['amp_grad_scaler'] = averaged_amp_grad_scaler\n",
    "            torch.save(checkpoint, fname)\n",
    "\n",
    "        self.remote_conf_data['workflow_form']['train_continue'] = True\n",
    "        print(federated_round, self.remote_conf_data['federated_form']['federated_total_rounds'])\n",
    "            \n",
    "kaapana_ft = nnUNetFederatedTraining(run_id='nnunet-federated-220315232240912342')\n",
    "kaapana_ft.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
